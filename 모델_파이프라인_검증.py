# -*- coding: utf-8 -*-
"""ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ê²€ì¦.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aBlp3b7vs8h5yRep-iJTU-pGNn68d0gm
"""

# OpenCV ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
!pip install opencv-python

# ======================================================================
# [ì‹¤ì „ ëª¨ë“œ] ì›ë³¸ ì´ë¯¸ì§€ ê¸°ë°˜ AI ì¶©ì¹˜ ì§„ë‹¨ê¸° (ìˆ˜ì •ë¨)
# ======================================================================
import os
import cv2
import numpy as np
import torch
import torch.nn as nn
from torchvision import models, transforms
import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
from PIL import Image
from google.colab import drive
from tqdm.auto import tqdm
import glob
import random

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸
if not os.path.exists('/content/drive'):
    drive.mount('/content/drive')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f">>> ì‘ì „ ì¥ë¹„: {device}")

# ======================================================================
# 1. ê²½ë¡œ ì„¤ì • (â˜…ìˆ˜ì • ì™„ë£Œ: Mydrive -> MyDriveâ˜…)
# ======================================================================
# í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” (ì§ì ‘ ë§Œë“œì‹œê³  ì´ë¯¸ì§€ë¥¼ ë„£ìœ¼ì„¸ìš”)
INPUT_DIR = '/content/UPdataset/validation/UPPERimages'
os.makedirs(INPUT_DIR, exist_ok=True)

# ê²°ê³¼ê°€ ì €ì¥ë  í´ë” (ë“œë¼ì´ë¸Œì— ì €ì¥í•˜ê³  ì‹¶ìœ¼ì‹  ê²ƒ ê°™ì•„ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤)
# â˜…â˜…â˜… ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ì…ë‹ˆë‹¤ â˜…â˜…â˜…
OUTPUT_DIR = '/content/drive/MyDrive/ëª¨í”„/inference_results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

# â˜… ëª¨ë¸ ê²½ë¡œ (Upper ëª¨ë¸ ê¸°ì¤€)
MASK_RCNN_PATH = '/content/drive/MyDrive/ëª¨í”„/í•™ìŠµëª¨ë¸/ì¹˜ì•„ë¶„í• _MaskRCNN_upper_512_best.pth'
CARIES_RESNET_PATH = "/content/drive/MyDrive/ëª¨í”„/í•™ìŠµëª¨ë¸/caries_classifier_upper_224_balanced_best.pth"

# ... (ì´í•˜ ëª¨ë¸ ì •ì˜ ë° ì¶”ë¡  ì½”ë“œëŠ” ë™ì¼í•©ë‹ˆë‹¤) ...

# ======================================================================
# 2. ëª¨ë¸ êµ¬ì¡° ì •ì˜
# ======================================================================
# --- Mask R-CNN ---
def get_model_instance_segmentation(num_classes):
    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=None)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
    hidden_layer = 256
    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)
    return model

# --- Caries Classifier (ResNet 224) ---
class CariesClassifier(nn.Module):
    def __init__(self, num_classes=1):
        super().__init__()
        try: self.base_model = models.resnet50(weights=None)
        except: self.base_model = models.resnet50(pretrained=False)

        self.base_model.fc = nn.Sequential(
            nn.Linear(self.base_model.fc.in_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, num_classes)
        )
    def forward(self, x): return self.base_model(x)

# ======================================================================
# 3. ëª¨ë¸ ë¡œë“œ
# ======================================================================
def load_models():
    print(">>> ëª¨ë¸ ë¡œë“œ ì¤‘...")

    # 1. Mask R-CNN
    det_model = get_model_instance_segmentation(num_classes=2).to(device)
    if os.path.exists(MASK_RCNN_PATH):
        det_model.load_state_dict(torch.load(MASK_RCNN_PATH, map_location=device))
        print("   - [ì™„ë£Œ] Mask R-CNN Loaded")
    else:
        print(f"   !!! ì˜¤ë¥˜: Mask R-CNN íŒŒì¼ ì—†ìŒ {MASK_RCNN_PATH}")
        return None, None
    det_model.eval()

    # 2. ResNet
    cls_model = CariesClassifier(1).to(device)
    if os.path.exists(CARIES_RESNET_PATH):
        try: cls_model.load_state_dict(torch.load(CARIES_RESNET_PATH, map_location=device))
        except: cls_model.load_state_dict(torch.load(CARIES_RESNET_PATH, map_location=device), strict=False)
        print("   - [ì™„ë£Œ] ResNet Loaded")
    else:
        print(f"   !!! ì˜¤ë¥˜: ResNet íŒŒì¼ ì—†ìŒ {CARIES_RESNET_PATH}")
        return None, None
    cls_model.eval()

    return det_model, cls_model

# ======================================================================
# 4. ì‹¤ì „ ì¶”ë¡  íŒŒì´í”„ë¼ì¸
# ======================================================================
def run_inference(detector, classifier, input_dir, output_dir):
    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸° (png, jpg, jpeg)
    image_files = glob.glob(os.path.join(input_dir, "*.png")) + \
                  glob.glob(os.path.join(input_dir, "*.jpg")) + \
                  glob.glob(os.path.join(input_dir, "*.jpeg"))

    if not image_files:
        print(f"\n!!! ê²½ê³ : '{input_dir}' í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("    ì´ë¯¸ì§€ë¥¼ í´ë”ì— ë„£ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    print(f"\n>>> ì‹¤ì „ ë¶„ì„ ì‹œì‘! (ëŒ€ìƒ: {len(image_files)}ê°œ)")

    # ì „ì²˜ë¦¬
    t_det = transforms.Compose([transforms.ToTensor()]) # Mask R-CNN
    t_cls = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    for img_path in tqdm(image_files, desc="Processing"):
        basename = os.path.basename(img_path)

        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img_bgr = cv2.imread(img_path)
            if img_bgr is None: continue
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            vis_img = img_bgr.copy()
        except: continue

        # 1. [íƒì§€] Mask R-CNN
        inp = t_det(Image.fromarray(img_rgb)).unsqueeze(0).to(device)
        with torch.no_grad():
            outputs = detector(inp)

        boxes = outputs[0]['boxes'].cpu().numpy()
        masks = outputs[0]['masks'].cpu().numpy()
        scores = outputs[0]['scores'].cpu().numpy()

        # 2. [ë¶„ë¥˜ ë° ì‹œê°í™”]
        tooth_count = 0
        caries_count = 0

        for i, score in enumerate(scores):
            if score > 0.5: # ì‹ ë¢°ë„ 50% ì´ìƒì¸ ë°•ìŠ¤ë§Œ
                tooth_count += 1

                # ì¢Œí‘œ ë° ë§ˆìŠ¤í¬
                x1, y1, x2, y2 = boxes[i].astype(int)
                mask_bin = (masks[i, 0] > 0.5).astype(np.uint8)

                # í¬ë¡­ (ì¢Œí‘œ ë³´ì • í¬í•¨)
                h, w = img_rgb.shape[:2]
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(w, x2), min(h, y2)

                crop = img_rgb[y1:y2, x1:x2]
                if crop.size == 0: continue

                # 3. [ì§„ë‹¨] ResNet
                with torch.no_grad():
                    out = classifier(t_cls(Image.fromarray(crop)).unsqueeze(0).to(device))
                    prob = torch.sigmoid(out).item()

                is_caries = prob > 0.5

                # --- ì‹œê°í™” ---
                if is_caries:
                    caries_count += 1
                    color = (0, 0, 255) # ë¹¨ê°•
                    status = "Caries"
                    conf_text = f"{prob*100:.1f}%"
                else:
                    color = (0, 255, 0) # ì´ˆë¡
                    status = "Normal"
                    conf_text = ""

                # 1) ë§ˆìŠ¤í¬ ìƒ‰ì¹  (ë°˜íˆ¬ëª…)
                roi = vis_img[mask_bin == 1]
                if roi.size > 0:
                    vis_img[mask_bin == 1] = (roi * 0.6 + np.array(color) * 0.4).astype(np.uint8)

                # 2) ì™¸ê³½ì„ 
                cnts, _ = cv2.findContours(mask_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(vis_img, cnts, -1, color, 2)

                # 3) ë°•ìŠ¤ ë° í…ìŠ¤íŠ¸
                cv2.rectangle(vis_img, (x1, y1), (x2, y2), color, 2)
                label = f"{status} {conf_text}"

                (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                cv2.rectangle(vis_img, (x1, y1 - 20), (x1 + tw, y1), color, -1)
                cv2.putText(vis_img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)

        # ê²°ê³¼ ì €ì¥
        save_name = f"Result_{caries_count}Caries_{basename}"
        cv2.imwrite(os.path.join(output_dir, save_name), vis_img)

    print("\n" + "="*60)
    print(f"ğŸ“¢ [ë¶„ì„ ì™„ë£Œ]")
    print(f"   - ê²°ê³¼ ì €ì¥ì†Œ: {output_dir}")
    print(f"   - ë¶„ì„í•œ ì´ë¯¸ì§€ ìˆ˜: {len(image_files)}ì¥")
    print("="*60)

# ======================================================================
# ì‹¤í–‰
# ======================================================================
det_net, cls_net = load_models()
if det_net and cls_net:
    run_inference(det_net, cls_net, INPUT_DIR, OUTPUT_DIR)

import os

# 1. ë“œë¼ì´ë¸Œê°€ ì•„ì§ ë§ˆìš´íŠ¸ ì•ˆ ë˜ì—ˆë‹¤ë©´ ìˆ˜í–‰ (ë˜ì–´ìˆë‹¤ë©´ ê±´ë„ˆëœë‹ˆë‹¤)
if not os.path.exists('/content/drive'):
    from google.colab import drive
    drive.mount('/content/drive')

# --- ì‘ì „ ê²½ë¡œ ì„¤ì • ---

# íƒ€ê²Ÿ íŒŒì¼ ê²½ë¡œ (êµ¬ê¸€ ë“œë¼ì´ë¸Œ)
src_zip_path = '/content/drive/MyDrive/3.á„€á…¢á„‡á…¡á†¼á„ƒá…¦á„‹á…µá„á…¥/1.á„ƒá…¦á„‹á…µá„á…¥/Validation/1.á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/4.upper.zip'

# ì••ì¶•ì„ í’€ ë¡œì»¬ ëª©ì ì§€ (Colab ë‚´ë¶€)
# ì´ë¦„ì´ ê²¹ì¹˜ì§€ ì•Šê²Œ 'images'ì™€ 'labels'ë¡œ í´ë”ë¥¼ ë‚˜ëˆ´ìŠµë‹ˆë‹¤.
src_dest = '/content/UPdataset/validation/UPPERimages'

# --- ì‘ì „ ê°œì‹œ (ì••ì¶• í•´ì œ) ---

print(f"ì‘ì „ 1: ì›ì²œ ë°ì´í„°(ì´ë¯¸ì§€) í•´ì œ ì¤‘... \n -> ëª©í‘œì§€ì : {src_dest}")
# í´ë” ìƒì„± (-p: ìƒìœ„ í´ë” ì—†ìœ¼ë©´ ê°™ì´ ìƒì„±)
!mkdir -p "{src_dest}"
# ì••ì¶• í•´ì œ (-qq: ì¡°ìš©íˆ, -d: ëª©ì ì§€ ì§€ì •)
!unzip -qq "{src_zip_path}" -d "{src_dest}"


print("======== ì‘ì „ ì„±ê³µ! ëª¨ë“  ë°ì´í„° ì „ê°œ ì™„ë£Œ! ========")

# ì¶©ì¹˜ ëª¨ë¸ ê²€ì¦ ë°ì´í„°ë¥¼ ì €ì¥í•  ëŒ€ìƒ ê²½ë¡œ ì„¤ì •
TARGET_DIR="/content/drive/MyDrive/ëª¨í”„/ê²€ì¦ë°ì´í„°/lower_nat"

# 1. ëŒ€ìƒ ê²½ë¡œ ìƒì„± (ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë¬´ì‹œ)
!mkdir -p "$TARGET_DIR"

# 2. ZIP íŒŒì¼ ì••ì¶• í•´ì œ
# -d ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì••ì¶• í•´ì œí•  ëŒ€ìƒ ë””ë ‰í† ë¦¬ ì§€ì •
!unzip /content/drive/MyDrive/3.á„€á…¢á„‡á…¡á†¼á„ƒá…¦á„‹á…µá„á…¥/1.á„ƒá…¦á„‹á…µá„á…¥/Validation/1.á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/5.lower.zip -d "$TARGET_DIR"

# 3. ì••ì¶• í•´ì œ ê²°ê³¼ í™•ì¸ (ì„ íƒ ì‚¬í•­)
!ls "$TARGET_DIR"

# ======================================================================
# 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
# ======================================================================
import os
import cv2
import torch
import torch.nn as nn
import numpy as np
from torchvision import transforms
from PIL import Image
from google.colab import drive
from tqdm.auto import tqdm
import glob
import random

if not os.path.exists('/content/drive'):
    drive.mount('/content/drive')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f">>> í˜„ì¬ ì‘ì „ ì¥ë¹„: {device}")

# ======================================================================
# 2. ê²½ë¡œ ì„¤ì • (FRONT ë°ì´í„°)
# ======================================================================
# ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
IMAGE_DIR = '/content/drive/MyDrive/3.ê°œë°©ë°ì´í„°/1.ë°ì´í„°/Training/1.ì›ì²œë°ì´í„°/2.front'
# ëª¨ë¸ ê²½ë¡œ
TOOTH_MODEL_PATH = "/content/drive/MyDrive/ëª¨í”„/í•™ìŠµëª¨ë¸/ì¹˜ì•„ì¢Œí‘œíƒì§€ëª¨ë¸_unet_pytorch_best.pth"
# ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ë””ë²„ê¹…ìš© í´ë”)
DEBUG_SAVE_DIR = "/content/drive/MyDrive/ëª¨í”„/ê²€ì¦ê²°ê³¼/ë””ë²„ê¹…_ë§ˆìŠ¤í¬_í™•ì¸"

# ======================================================================
# 3. ëª¨ë¸ êµ¬ì¡° (U-Net) - ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ í¬í•¨
# ======================================================================
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True)
        )
    def forward(self, x): return self.double_conv(x)

class Down(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(nn.MaxPool2d(2), DoubleConv(in_channels, out_channels))
    def forward(self, x): return self.maxpool_conv(x)

class Up(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
        self.conv = DoubleConv(in_channels, out_channels)
    def forward(self, x1, x2):
        x1 = self.up(x1)
        dy = x2.size()[2]-x1.size()[2]; dx = x2.size()[3]-x1.size()[3]
        x1 = torch.nn.functional.pad(x1, [dx//2, dx-dx//2, dy//2, dy-dy//2])
        return self.conv(torch.cat([x2, x1], dim=1))

class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)
    def forward(self, x): return self.conv(x)

class UNet(nn.Module):
    def __init__(self, n_channels=3, n_classes=1):
        super().__init__()
        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128); self.down2 = Down(128, 256)
        self.down3 = Down(256, 512); self.down4 = Down(512, 1024)
        self.up1 = Up(1024, 512); self.up2 = Up(512, 256)
        self.up3 = Up(256, 128); self.up4 = Up(128, 64)
        self.outc = OutConv(64, n_classes)
    def forward(self, x):
        x1=self.inc(x); x2=self.down1(x1); x3=self.down2(x2); x4=self.down3(x3); x5=self.down4(x4)
        x=self.up1(x5,x4); x=self.up2(x,x3); x=self.up3(x,x2); x=self.up4(x,x1)
        return self.outc(x)

# ======================================================================
# 4. ë§ˆìŠ¤í¬ ì¶”ì¶œ ë° ì €ì¥ í•¨ìˆ˜
# ======================================================================
def extract_and_save_masks(num_samples=50):
    print(f">>> ğŸ•µï¸â€â™‚ï¸ ë§ˆìŠ¤í¬ ìƒíƒœ ì •ë°€ ì§„ë‹¨ ì‹œì‘ (ìƒ˜í”Œë§: {num_samples}ì¥)")

    # ì €ì¥ í´ë” ìƒì„±
    os.makedirs(DEBUG_SAVE_DIR, exist_ok=True)

    # ëª¨ë¸ ë¡œë“œ
    model = UNet(3, 1).to(device)
    if os.path.exists(TOOTH_MODEL_PATH):
        model.load_state_dict(torch.load(TOOTH_MODEL_PATH, map_location=device))
        print("   - ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    else:
        print("!!! ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    model.eval()

    # ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ëœë¤ ìƒ˜í”Œë§)
    all_images = glob.glob(os.path.join(IMAGE_DIR, "*.png"))
    if len(all_images) > num_samples:
        target_files = random.sample(all_images, num_samples)
    else:
        target_files = all_images

    transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

    for img_path in tqdm(target_files, desc="Generating Masks"):
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img_bgr = cv2.imread(img_path)
            if img_bgr is None: continue
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            h, w = img_bgr.shape[:2]
            basename = os.path.splitext(os.path.basename(img_path))[0]

            # ì¶”ë¡  (Inference)
            inp = transform(Image.fromarray(img_rgb)).unsqueeze(0).to(device)
            with torch.no_grad():
                # Sigmoidë¥¼ í†µê³¼ì‹œì¼œ í™•ë¥ ë§µ(0~1) ìƒì„±
                mask_prob = torch.sigmoid(model(inp)).cpu().numpy()[0, 0]

            # ì›ë³¸ í¬ê¸°ë¡œ ë³µì› (ì¤‘ìš”: ì—¬ê¸°ì„œ ë–¡ì§ í˜„ìƒì´ ê°€ì†í™”ë  ìˆ˜ ìˆìŒ)
            mask_resized = cv2.resize(mask_prob, (w, h), interpolation=cv2.INTER_LINEAR)

            # ì´ì§„í™” (Threshold 0.5) -> 0 ë˜ëŠ” 255
            mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255

            # 1. ìˆœìˆ˜ ë§ˆìŠ¤í¬ ì €ì¥ (í‘ë°±)
            cv2.imwrite(os.path.join(DEBUG_SAVE_DIR, f"Pure_Mask_{basename}.png"), mask_binary)

            # 2. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„± (ë¹¨ê°„ìƒ‰ ë§ˆìŠ¤í¬)
            # ë§ˆìŠ¤í¬ê°€ ìˆëŠ” ë¶€ë¶„ë§Œ ë¹¨ê°„ìƒ‰ì„ ì…í˜
            overlay = img_bgr.copy()
            # BGRì—ì„œ Red ì±„ë„(2)ë§Œ 255ë¡œ, ë‚˜ë¨¸ì§€ëŠ” ìœ ì§€í•˜ë©´ì„œ íˆ¬ëª…ë„ ì ìš©
            overlay[mask_binary == 255] = [0, 0, 255]

            # ì›ë³¸ê³¼ ì˜¤ë²„ë ˆì´ í•©ì„± (íˆ¬ëª…ë„ 0.4)
            final_vis = cv2.addWeighted(overlay, 0.4, img_bgr, 0.6, 0)

            cv2.imwrite(os.path.join(DEBUG_SAVE_DIR, f"Overlay_{basename}.jpg"), final_vis)

        except Exception as e:
            print(f"Error processing {img_path}: {e}")
            continue

    print("\n" + "="*60)
    print("ğŸ“¢ [ì§„ë‹¨ ì™„ë£Œ]")
    print(f"   - ì €ì¥ ê²½ë¡œ: {DEBUG_SAVE_DIR}")
    print("   - í™•ì¸ ë°©ë²•: 'Pure_Mask' ì´ë¯¸ì§€ë¥¼ ì—´ì–´ ì¹˜ì•„ê°€ ë¶„ë¦¬ë˜ì–´ ìˆëŠ”ì§€,")
    print("                í•˜ë‚˜ì˜ ë©ì–´ë¦¬(Blob)ë¡œ ë­‰ì³ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.")
    print("="*60)

# ì‹¤í–‰
extract_and_save_masks(num_samples=20) # 20ì¥ë§Œ ë¹ ë¥´ê²Œ í™•ì¸

import os
import json
import glob
from tqdm import tqdm

# ê²€ì¦ìš© JSON íŒŒì¼ë“¤ì´ ìœ„ì¹˜í•œ ê²½ë¡œ
JSON_DIR = '/content/drive/MyDrive/ëª¨í”„/ê²€ì¦ë°ì´í„°/front_val'

def inspect_caries_data(json_dir):
    json_files = glob.glob(os.path.join(json_dir, "*.json"))
    print(f">>> ì •ë°€ ìˆ˜ìƒ‰ ì‹œì‘: ì´ {len(json_files)}ê°œì˜ íŒŒì¼ ë¶„ì„ ì¤‘...\n")

    total_teeth = 0
    decayed_count = 0
    normal_count = 0

    # ì¶©ì¹˜ê°€ í¬í•¨ëœ íŒŒì¼ëª…ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    files_with_caries = []

    for json_path in tqdm(json_files, desc="ë¶„ì„ ì¤‘"):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            has_decayed_in_file = False

            # ê° íŒŒì¼ ë‚´ì˜ ì¹˜ì•„ ì •ë³´ ìˆœíšŒ
            for tooth in data.get('tooth', []):
                total_teeth += 1
                is_decayed = tooth.get('decayed', False)

                if is_decayed:
                    decayed_count += 1
                    has_decayed_in_file = True
                else:
                    normal_count += 1

            # ì´ íŒŒì¼ì— ì¶©ì¹˜ ì¹˜ì•„ê°€ í•˜ë‚˜ë¼ë„ ìˆì—ˆë‹¤ë©´ ëª©ë¡ì— ì¶”ê°€
            if has_decayed_in_file:
                files_with_caries.append(os.path.basename(json_path))

        except Exception as e:
            print(f"!!! íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {json_path} - {e}")

    # === ìµœì¢… ë³´ê³  ===
    print("\n" + "="*50)
    print("ğŸ“Š [ë°ì´í„°ì…‹ ë¶„ì„ ê²°ê³¼ ë³´ê³ ]")
    print(f"   - ì´ íŒŒì¼ ìˆ˜: {len(json_files)}ê°œ")
    print(f"   - ì´ ì¹˜ì•„ ìˆ˜: {total_teeth}ê°œ")
    print("-" * 30)
    print(f"   âœ… ì •ìƒ ì¹˜ì•„ (Normal): {normal_count}ê°œ")
    print(f"   ğŸ¦  ì¶©ì¹˜ ì¹˜ì•„ (Caries): {decayed_count}ê°œ")
    print("-" * 30)

    if total_teeth > 0:
        decay_ratio = (decayed_count / total_teeth) * 100
        print(f"   ğŸ“ˆ ì¶©ì¹˜ ë¹„ìœ¨: {decay_ratio:.2f}%")

    if decayed_count == 0:
        print("\nğŸš¨ [ê¸´ê¸‰] ì´ ë°ì´í„°ì…‹ì—ëŠ” ì¶©ì¹˜(True) ë¼ë²¨ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤!")
        print("   -> ê²€ì¦ ë°ì´í„°ì…‹ì„ êµì²´í•˜ê±°ë‚˜ ë¼ë²¨ë§ì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        print(f"\nğŸ“‚ ì¶©ì¹˜ê°€ ë°œê²¬ëœ íŒŒì¼ ëª©ë¡ ({len(files_with_caries)}ê°œ):")
        # ë„ˆë¬´ ë§ìœ¼ë©´ ì•ì˜ 10ê°œë§Œ ì¶œë ¥
        for i, fname in enumerate(files_with_caries[:10]):
            print(f"   {i+1}. {fname}")
        if len(files_with_caries) > 10:
            print(f"   ... ì™¸ {len(files_with_caries)-10}ê°œ íŒŒì¼")

    print("="*50)

# í•¨ìˆ˜ ì‹¤í–‰
inspect_caries_data(JSON_DIR)

import os
import json
import glob
from tqdm import tqdm

# ê²½ë¡œ ì„¤ì • (Front ë°ì´í„°)
FULL_JSON_DIR = '/content/drive/MyDrive/ëª¨í”„ êµ¬ê°• ë°ì´í„°/front'
TRAIN_LIST_PATH = '/content/drive/MyDrive/ëª¨í”„/íŒŒì¼ë¦¬ìŠ¤íŠ¸_front/file_pairs_list_50k.json'

def find_unseen_caries_files(json_dir, train_list_path):
    print(">>> ğŸ•µï¸â€â™‚ï¸ 'ë¯¸ì‚¬ìš© ì¶©ì¹˜ ë°ì´í„°' ì •ë°€ ìˆ˜ìƒ‰ ì‹œì‘...")

    # 1. í•™ìŠµ íŒŒì¼ëª… ì§‘í•© ìƒì„±
    train_filenames = set()
    if os.path.exists(train_list_path):
        with open(train_list_path, 'r') as f:
            train_data = json.load(f)
        for item in train_data:
            fname = os.path.splitext(os.path.basename(item['image_path']))[0]
            train_filenames.add(fname)
    else:
        print("!!! í•™ìŠµ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ì „ì²´ íŒŒì¼ ìŠ¤ìº”
    all_files = glob.glob(os.path.join(json_dir, "*.json"))
    unseen_caries_files = []
    unseen_normal_count = 0

    for json_path in tqdm(all_files, desc="Searching"):
        base_name = os.path.splitext(os.path.basename(json_path))[0]

        # í•™ìŠµì— ì•ˆ ì“´ íŒŒì¼(Unseen)ë§Œ í™•ì¸
        if base_name not in train_filenames:
            try:
                with open(json_path, 'r') as f:
                    data = json.load(f)

                # ì¶©ì¹˜ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
                has_caries = False
                for tooth in data.get('tooth', []):
                    if tooth.get('decayed', False):
                        has_caries = True
                        break

                if has_caries:
                    unseen_caries_files.append(json_path)
                else:
                    unseen_normal_count += 1

            except: continue

    # 3. ê²°ê³¼ ë³´ê³ 
    print("\n" + "="*50)
    print(f"ğŸ” [ìˆ˜ìƒ‰ ê²°ê³¼ ë³´ê³ ]")
    print(f"   - í•™ìŠµì— ì•ˆ ì“´ íŒŒì¼ ì´ ê°œìˆ˜: {unseen_normal_count + len(unseen_caries_files)}ê°œ")
    print("-" * 30)
    print(f"   âœ… ì •ìƒ íŒŒì¼ (ì¶©ì¹˜ X): {unseen_normal_count}ê°œ")
    print(f"   ğŸ¦  ì¶©ì¹˜ í¬í•¨ íŒŒì¼ (ì¶©ì¹˜ O): {len(unseen_caries_files)}ê°œ")
    print("="*50)

    if len(unseen_caries_files) == 0:
        print("\nğŸš¨ [ë¹„ìƒ] í•™ìŠµ ì•ˆ í•œ ë°ì´í„°ì—ëŠ” ì¶©ì¹˜ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤!")
        print("   -> í•´ê²°ì±…: í•™ìŠµ ë°ì´í„°(50k) ì¤‘ì—ì„œ ì¼ë¶€(Test set)ë¥¼ ë–¼ì–´ë‚´ì„œ ê²€ì¦í•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        print(f"\n>>> ë°œê²¬ëœ ë¯¸ì‚¬ìš© ì¶©ì¹˜ íŒŒì¼ {len(unseen_caries_files)}ê°œë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì‹œ ê²€ì¦í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        return unseen_caries_files

# ì‹¤í–‰
unseen_caries_list = find_unseen_caries_files(FULL_JSON_DIR, TRAIN_LIST_PATH)

# ======================================================================
# [1ë‹¨ê³„] ì¹˜ì•„ íƒì§€ ë° í¬ë¡­ ì €ì¥ (512x512 ëª¨ë¸ ì‚¬ìš©)
# ======================================================================
import os
import json
import cv2
import numpy as np
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
from tqdm.auto import tqdm
import glob
import random

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸
if not os.path.exists('/content/drive'):
    from google.colab import drive
    drive.mount('/content/drive')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f">>> í˜„ì¬ ì‘ì „ ì¥ë¹„: {device}")

# ----------------------------------------------------------------------
# 1. ì„¤ì • (ê²½ë¡œ í™•ì¸)
# ----------------------------------------------------------------------
IMAGE_DIR = '/content/drive/MyDrive/3.ê°œë°©ë°ì´í„°/1.ë°ì´í„°/Training/1.ì›ì²œë°ì´í„°/2.front'
JSON_DIR = '/content/drive/MyDrive/ëª¨í”„ êµ¬ê°• ë°ì´í„°/front'
TRAIN_LIST_PATH = '/content/drive/MyDrive/ëª¨í”„/íŒŒì¼ë¦¬ìŠ¤íŠ¸_front/file_pairs_list_50k.json'

# â˜… íƒì§€ ëª¨ë¸: 512 í•´ìƒë„ ë²„ì „ ì‚¬ìš©
TOOTH_MODEL_PATH = '/content/drive/MyDrive/ëª¨í”„/í•™ìŠµëª¨ë¸/ì¹˜ì•„ì¢Œí‘œíƒì§€ëª¨ë¸_unet_front_512.pth'

# â˜… ì¤‘ê°„ ë°ì´í„° ì €ì¥ì†Œ (ë‹¤ë¦¬ ì—­í• )
INTERMEDIATE_DIR = "/content/drive/MyDrive/ëª¨í”„/ì¤‘ê°„_í¬ë¡­_ë°ì´í„°_128ìš©"
os.makedirs(INTERMEDIATE_DIR, exist_ok=True)

# ----------------------------------------------------------------------
# 2. U-Net ëª¨ë¸ êµ¬ì¡° (í•™ìŠµ ì½”ë“œì™€ ë™ì¼)
# ----------------------------------------------------------------------
class DoubleConv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.double_conv = nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, 1, 1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, 1, 1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))
    def forward(self, x): return self.double_conv(x)
class Down(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__(); self.maxpool_conv = nn.Sequential(nn.MaxPool2d(2), DoubleConv(in_ch, out_ch))
    def forward(self, x): return self.maxpool_conv(x)
class Up(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__(); self.up = nn.ConvTranspose2d(in_ch, in_ch//2, 2, 2); self.conv = DoubleConv(in_ch, out_ch)
    def forward(self, x1, x2):
        x1 = self.up(x1); diffY = x2.size()[2]-x1.size()[2]; diffX = x2.size()[3]-x1.size()[3]
        x1 = torch.nn.functional.pad(x1, [diffX//2, diffX-diffX//2, diffY//2, diffY-diffY//2]); return self.conv(torch.cat([x2, x1], dim=1))
class OutConv(nn.Module):
    def __init__(self, in_ch, out_ch): super().__init__(); self.conv = nn.Conv2d(in_ch, out_ch, 1)
    def forward(self, x): return self.conv(x)
class UNet(nn.Module):
    def __init__(self, n_channels=3, n_classes=1):
        super().__init__(); self.inc = DoubleConv(n_channels, 64); self.down1 = Down(64, 128); self.down2 = Down(128, 256); self.down3 = Down(256, 512); self.down4 = Down(512, 1024); self.up1 = Up(1024, 512); self.up2 = Up(512, 256); self.up3 = Up(256, 128); self.up4 = Up(128, 64); self.outc = OutConv(64, n_classes)
    def forward(self, x): x1=self.inc(x); x2=self.down1(x1); x3=self.down2(x2); x4=self.down3(x3); x5=self.down4(x4); x=self.up1(x5,x4); x=self.up2(x,x3); x=self.up3(x,x2); x=self.up4(x,x1); return self.outc(x)

# ----------------------------------------------------------------------
# 3. ì›Œí„°ì‰ë“œ ë° ìœ í‹¸ë¦¬í‹°
# ----------------------------------------------------------------------
def separate_teeth_watershed(mask_binary):
    dist_transform = cv2.distanceTransform(mask_binary, cv2.DIST_L2, 5)
    ret, sure_fg = cv2.threshold(dist_transform, 0.3 * dist_transform.max(), 255, 0) # ì„ê³„ê°’ 0.3
    sure_fg = np.uint8(sure_fg)
    sure_bg = cv2.dilate(mask_binary, np.ones((3,3), np.uint8), iterations=3)
    unknown = cv2.subtract(sure_bg, sure_fg)
    ret, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown == 255] = 0
    dummy_img = cv2.cvtColor(mask_binary, cv2.COLOR_GRAY2BGR)
    markers = cv2.watershed(dummy_img, markers)

    boxes = []
    for label in np.unique(markers):
        if label <= 1: continue
        temp_mask = np.zeros_like(mask_binary)
        temp_mask[markers == label] = 255
        cnts, _ = cv2.findContours(temp_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for c in cnts:
            x, y, w, h = cv2.boundingRect(c)
            if w > 15 and h > 15: boxes.append([x, y, w, h])
    return boxes

def calculate_iou(boxA, boxB):
    xA, yA = max(boxA[0], boxB[0]), max(boxA[1], boxB[1])
    xB, yB = min(boxA[0]+boxA[2], boxB[0]+boxB[2]), min(boxA[1]+boxA[3], boxB[1]+boxB[3])
    inter = max(0, xB-xA) * max(0, yB-yA)
    return inter / float(boxA[2]*boxA[3] + boxB[2]*boxB[3] - inter + 1e-6)

# ----------------------------------------------------------------------
# 4. 1ë‹¨ê³„ ì‹¤í–‰ í•¨ìˆ˜
# ----------------------------------------------------------------------
def run_step1():
    print(">>> [1ë‹¨ê³„] ì¹˜ì•„ íƒì§€ ë° í¬ë¡­ ì‹œì‘...")

    # ëª¨ë¸ ë¡œë“œ
    model = UNet(3, 1).to(device)
    if os.path.exists(TOOTH_MODEL_PATH):
        model.load_state_dict(torch.load(TOOTH_MODEL_PATH, map_location=device))
        print(f"   - 512 íƒì§€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    else:
        print("!!! íƒì§€ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    model.eval()

    # ë°ì´í„° ì„ ë³„ (Unseen)
    train_set = set()
    if os.path.exists(TRAIN_LIST_PATH):
        with open(TRAIN_LIST_PATH) as f:
            for i in json.load(f): train_set.add(os.path.splitext(os.path.basename(i['image_path']))[0])

    all_files = glob.glob(os.path.join(JSON_DIR, "*.json"))
    target_files = []
    for p in all_files:
        if os.path.splitext(os.path.basename(p))[0] not in train_set:
            target_files.append(p)

    # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 1000ê°œë§Œ ì œí•œ (ì›í•˜ì‹œë©´ ì´ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬í•˜ì„¸ìš”)
    target_files = target_files[:1000]
    print(f"   - ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼: {len(target_files)}ê°œ")

    transform = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])
    count = 0

    for json_path in tqdm(target_files, desc="Step 1 Processing"):
        base = os.path.splitext(os.path.basename(json_path))[0]
        img_path = os.path.join(IMAGE_DIR, base + ".png")
        if not os.path.exists(img_path): continue

        try:
            img_bgr = cv2.imread(img_path)
            if img_bgr is None: continue
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            h, w = img_bgr.shape[:2]
        except: continue

        # ì¶”ë¡  (512)
        inp = transform(Image.fromarray(img_rgb)).unsqueeze(0).to(device)
        with torch.no_grad():
            mask = (torch.sigmoid(model(inp)) > 0.5).float().cpu().numpy()[0, 0]

        # ì›Œí„°ì‰ë“œ ë¶„í• 
        mask_uint8 = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST).astype(np.uint8) * 255
        pred_boxes = separate_teeth_watershed(mask_uint8)

        # GT ë§¤ì¹­ ë° í¬ë¡­
        with open(json_path) as f: data = json.load(f)

        for t in data.get('tooth', []):
            gseg = np.array(t.get('segmentation', []), np.int32)
            if len(gseg)==0: continue
            gbox = cv2.boundingRect(gseg)
            gdec = 1 if t.get('decayed') else 0
            t_num = t.get('teeth_num', 0)

            best_iou, best_box = 0, None
            for pb in pred_boxes:
                iou = calculate_iou(gbox, pb)
                if iou > best_iou: best_iou, best_box = iou, pb

            if best_iou > 0.1 and best_box:
                bx, by, bw, bh = best_box
                crop = img_rgb[by:by+bh, bx:bx+bw]
                if crop.size == 0: continue

                # ì €ì¥: íŒŒì¼ëª…ì— ì •ë‹µ(GT) í¬í•¨
                save_name = f"{base}_{t_num}_GT{gdec}.png"
                cv2.imwrite(os.path.join(INTERMEDIATE_DIR, save_name), cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))
                count += 1

    print(f"\n>>> [1ë‹¨ê³„ ì™„ë£Œ] {count}ê°œì˜ ì¹˜ì•„ ì´ë¯¸ì§€ê°€ '{INTERMEDIATE_DIR}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 1ë‹¨ê³„ ì‹¤í–‰
run_step1()

# ======================================================================
# [2ë‹¨ê³„] ì¶©ì¹˜ ë¶„ë¥˜ ë° ì„±ëŠ¥ í‰ê°€ (128x128 ëª¨ë¸ ì‚¬ìš©)
# ======================================================================
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# ----------------------------------------------------------------------
# 1. ì„¤ì •
# ----------------------------------------------------------------------
# â˜… ë¶„ë¥˜ ëª¨ë¸: ê¸°ì¡´ 128 í•´ìƒë„ ë²„ì „ ì‚¬ìš©
CARIES_MODEL_PATH = "/content/drive/MyDrive/ëª¨í”„/í•™ìŠµëª¨ë¸/caries_detection_model_front_50k_best_pytorch.pth"
# ì¤‘ê°„ ë°ì´í„° ì €ì¥ì†Œ (1ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ê³³)
INTERMEDIATE_DIR = "/content/drive/MyDrive/ëª¨í”„/ì¤‘ê°„_í¬ë¡­_ë°ì´í„°_128ìš©"

# ----------------------------------------------------------------------
# 2. ResNet ëª¨ë¸ êµ¬ì¡° (128 í•™ìŠµ ë•Œ ì‚¬ìš©í•œ êµ¬ì¡°)
# ----------------------------------------------------------------------
class CariesClassifier(nn.Module):
    def __init__(self, num_classes=1):
        super().__init__()
        try: self.base_model = models.resnet50(weights='DEFAULT')
        except: self.base_model = models.resnet50(weights='IMAGENET1K_V1')

        # â˜… ì¤‘ìš”: ê¸°ì¡´ 128 ëª¨ë¸ì˜ FC ë ˆì´ì–´ êµ¬ì¡°ì™€ ì¼ì¹˜ì‹œì¼œì•¼ í•¨
        # (ê°€ì¤‘ì¹˜ ë¡œë“œ ì—ëŸ¬ ë°©ì§€)
        num_ftrs = self.base_model.fc.in_features
        self.base_model.fc = nn.Sequential(
            nn.Linear(num_ftrs, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes),
            nn.Sigmoid() # ê¸°ì¡´ ëª¨ë¸ì€ Sigmoidê°€ í¬í•¨ë˜ì–´ ìˆì„ í™•ë¥ ì´ ë†’ìŒ
        )
    def forward(self, x): return self.base_model(x)

# ----------------------------------------------------------------------
# 3. 2ë‹¨ê³„ ì‹¤í–‰ í•¨ìˆ˜
# ----------------------------------------------------------------------
def run_step2():
    print("\n>>> [2ë‹¨ê³„] ì¶©ì¹˜ ë¶„ë¥˜ ë° ì±„ì  ì‹œì‘...")

    # ëª¨ë¸ ë¡œë“œ
    model = CariesClassifier(1).to(device)
    if os.path.exists(CARIES_MODEL_PATH):
        # Strict=Falseë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ì„¸í•œ ë ˆì´ì–´ ì´ë¦„ ì°¨ì´ê°€ ìˆì–´ë„ ë¡œë“œ ì‹œë„
        # (ë§Œì•½ fc ë ˆì´ì–´ ì´ë¦„ì´ ì•ˆ ë§ìœ¼ë©´ ì˜¤ë¥˜ ë‚  ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸ í•„ìš”)
        try:
            model.load_state_dict(torch.load(CARIES_MODEL_PATH, map_location=device))
        except:
            # í‚¤ ë¶ˆì¼ì¹˜ ì‹œ 'model' í‚¤ í™•ì¸
            state = torch.load(CARIES_MODEL_PATH, map_location=device)
            if 'model' in state: model.load_state_dict(state['model'])
            else: model.load_state_dict(state, strict=False)

        print(f"   - 128 ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    else:
        print("!!! ë¶„ë¥˜ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    model.eval()

    # ë°ì´í„° ë¡œë“œ
    crop_files = glob.glob(os.path.join(INTERMEDIATE_DIR, "*.png"))
    if not crop_files:
        print("!!! ê²€ì¦í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 1ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    print(f"   - ê²€ì¦ ëŒ€ìƒ: {len(crop_files)}ê°œ ì¹˜ì•„")

    # ì „ì²˜ë¦¬ (128 í•´ìƒë„)
    transform = transforms.Compose([
        transforms.Resize((128, 128)), # â˜… 128ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    y_true = []
    y_pred = []

    for path in tqdm(crop_files, desc="Step 2 Classifying"):
        try:
            # íŒŒì¼ëª…ì—ì„œ ì •ë‹µ(GT) ì¶”ì¶œ: image_11_GT1.png -> 1
            filename = os.path.basename(path)
            gt_part = filename.split("_GT")[1] # "1.png"
            gt_label = int(gt_part.split(".")[0]) # 1

            # ì¶”ë¡ 
            img = Image.open(path).convert("RGB")
            inp = transform(img).unsqueeze(0).to(device)

            with torch.no_grad():
                out = model(inp) # Sigmoidê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ 0~1 ê°’ ì¶œë ¥
                prob = out.item()
                pred = 1 if prob > 0.5 else 0

            y_true.append(gt_label)
            y_pred.append(pred)
        except Exception as e:
            continue

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    if len(y_true) > 0:
        print("[ìµœì¢… ì„±ì í‘œ (128 ResNet)]")
        print(classification_report(y_true, y_pred, target_names=['Normal', 'Caries']))

        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(6, 5))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Caries'], yticklabels=['Normal', 'Caries'])
        plt.title('Confusion Matrix (128 ResNet)')
        plt.show()
    else:
        print("!!! ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    print("="*60)

# 2ë‹¨ê³„ ì‹¤í–‰
run_step2()