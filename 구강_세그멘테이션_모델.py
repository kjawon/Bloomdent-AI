# -*- coding: utf-8 -*-
"""êµ¬ê°• ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wzxraSV9mzc5vkFOYTPK08FzEkfvuY_q
"""

# ================================================================= #
# [LOWER] Mask R-CNN ì¹˜ì•„ ë¶„í•  í•™ìŠµ (ì•ˆì •ì„± + Best Model ì €ì¥)
# ================================================================= #
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
from PIL import Image
import os
import glob
from tqdm.auto import tqdm
import json
import numpy as np
import cv2
import sys

# Google Drive ë§ˆìš´íŠ¸
if not os.path.exists('/content/drive'):
    from google.colab import drive
    drive.mount('/content/drive')

# ================================================================= #
# 1. ê²½ë¡œ ë° ì„¤ì • (LOWER ë°ì´í„°ë¡œ ë³€ê²½ë¨)
# ================================================================= #
# JSON íŒŒì¼ ê²½ë¡œ (Lower)
JSON_REFERENCE_DIR = '/content/lowerdataset/train/lowerlabels'
# ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (Lower)
ORIGINAL_IMAGE_DIR = '/content/lowerdataset/train/lowerimages'

# í•™ìŠµ ì„¤ì •
IMAGE_SIZE = (512, 512)
BATCH_SIZE = 4
EPOCHS = 30
LEARNING_RATE = 0.005
NUM_TRAINING_FILES = 16000

# ì €ì¥ ê²½ë¡œ ì„¤ì •
SAVE_DIR = '/content/drive/MyDrive/ëª¨í”„/í•™ìŠµëª¨ë¸/'
os.makedirs(SAVE_DIR, exist_ok=True)

# â˜…â˜…â˜… íŒŒì¼ëª… ë³€ê²½: upper -> lower â˜…â˜…â˜…
FINAL_SAVE_PATH = os.path.join(SAVE_DIR, 'ì¹˜ì•„ë¶„í• _MaskRCNN_lower_512_final.pth')
BEST_SAVE_PATH = os.path.join(SAVE_DIR, 'ì¹˜ì•„ë¶„í• _MaskRCNN_lower_512_best.pth')

# ì¥ë¹„ ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f">>> ì‘ì „ ì¥ë¹„: {device} | ëª©í‘œ: LOWER Mask R-CNN í•™ìŠµ (Workers=0)")

# ================================================================= #
# 2. Dataset í´ë˜ìŠ¤ (ë™ì¼í•¨)
# ================================================================= #
class ToothInstanceDataset(Dataset):
    def __init__(self, img_dir, json_dir, num_files=None, width=512, height=512):
        self.img_dir = img_dir
        self.json_dir = json_dir
        self.width = width
        self.height = height
        self.imgs = []
        self.jsons = []

        print(f">>> ë°ì´í„° ë§¤ì¹­ ì‹œì‘ (Lower)...")
        all_json_files = sorted(glob.glob(os.path.join(json_dir, '*.json')))

        if len(all_json_files) == 0:
            print("!!! ê²½ê³ : JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤ !!!")

        if num_files:
            all_json_files = all_json_files[:min(num_files, len(all_json_files))]

        for j_path in tqdm(all_json_files, desc="Matching"):
            base_name = os.path.splitext(os.path.basename(j_path))[0]
            img_path = os.path.join(img_dir, f"{base_name}.png")

            if os.path.exists(img_path):
                self.imgs.append(img_path)
                self.jsons.append(j_path)

        print(f">>> ì´ {len(self.imgs)}ìŒì˜ ë°ì´í„° ì¥ì „ ì™„ë£Œ!")

    def __len__(self): return len(self.imgs)

    def __getitem__(self, idx):
        img_path = self.imgs[idx]
        json_path = self.jsons[idx]

        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(img_path)
        if img is None:
            return self.__getitem__((idx + 1) % len(self.imgs))

        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        orig_h, orig_w = img.shape[:2]

        with open(json_path, 'r') as f: data = json.load(f)

        boxes, masks, labels = [], [], []

        for tooth in data.get('tooth', []):
            seg = np.array(tooth.get('segmentation', []), dtype=np.int32)
            if len(seg) == 0: continue

            mask = np.zeros((orig_h, orig_w), dtype=np.uint8)
            cv2.fillPoly(mask, [seg], 1)

            x, y, w, h = cv2.boundingRect(seg)
            if w < 2 or h < 2: continue

            boxes.append([x, y, x+w, y+h])
            masks.append(mask)
            labels.append(1)

        img_resized = cv2.resize(img, (self.width, self.height))
        img_tensor = transforms.ToTensor()(img_resized)

        target_masks, target_boxes = [], []
        rx = self.width / orig_w
        ry = self.height / orig_h

        for i in range(len(masks)):
            m = cv2.resize(masks[i], (self.width, self.height), interpolation=cv2.INTER_NEAREST)
            target_masks.append(m)
            xmin = boxes[i][0] * rx
            ymin = boxes[i][1] * ry
            xmax = boxes[i][2] * rx
            ymax = boxes[i][3] * ry
            target_boxes.append([xmin, ymin, xmax, ymax])

        if len(target_boxes) > 0:
            boxes_tensor = torch.as_tensor(target_boxes, dtype=torch.float32)
            labels_tensor = torch.as_tensor(labels, dtype=torch.int64)
            masks_tensor = torch.as_tensor(np.array(target_masks), dtype=torch.uint8)

            image_id = torch.tensor([idx])
            area = (boxes_tensor[:, 3] - boxes_tensor[:, 1]) * (boxes_tensor[:, 2] - boxes_tensor[:, 0])
            iscrowd = torch.zeros((len(labels),), dtype=torch.int64)

            target = {}
            target["boxes"] = boxes_tensor
            target["labels"] = labels_tensor
            target["masks"] = masks_tensor
            target["image_id"] = image_id
            target["area"] = area
            target["iscrowd"] = iscrowd
        else:
            target = {
                "boxes": torch.zeros((0, 4), dtype=torch.float32),
                "labels": torch.zeros((0,), dtype=torch.int64),
                "masks": torch.zeros((0, self.height, self.width), dtype=torch.uint8),
                "image_id": torch.tensor([idx]),
                "area": torch.zeros((0,), dtype=torch.float32),
                "iscrowd": torch.zeros((0,), dtype=torch.int64)
            }
        return img_tensor, target

def collate_fn(batch): return tuple(zip(*batch))

# ================================================================= #
# 3. ëª¨ë¸ ë° í›ˆë ¨ ë£¨í”„
# ================================================================= #
def get_model_instance_segmentation(num_classes):
    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights="DEFAULT")
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
    hidden_layer = 256
    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)
    return model

def train_mask_rcnn():
    dataset = ToothInstanceDataset(ORIGINAL_IMAGE_DIR, JSON_REFERENCE_DIR, num_files=NUM_TRAINING_FILES, width=IMAGE_SIZE[0], height=IMAGE_SIZE[1])

    if len(dataset) == 0:
        print("!!! ì‘ì „ ì¤‘ì§€: ë¡œì»¬ ê²½ë¡œì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ !!!")
        return

    train_size = int(0.9 * len(dataset))
    val_size = len(dataset) - train_size
    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])

    # num_workers=0
    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)

    model = get_model_instance_segmentation(num_classes=2)
    model.to(device)

    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=0.9, weight_decay=0.0005)
    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

    print(f"\n>>> ğŸš€ Mask R-CNN [LOWER] í›ˆë ¨ ê°œì‹œ! (ì´ {EPOCHS} ì—í­)")

    best_loss = float('inf')

    for epoch in range(EPOCHS):
        model.train()
        epoch_loss = 0
        progress = tqdm(train_loader, desc=f"Ep {epoch+1}/{EPOCHS}", mininterval=10.0)

        for images, targets in progress:
            images = list(image.to(device) for image in images)
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            loss_dict = model(images, targets)
            losses = sum(loss for loss in loss_dict.values())

            optimizer.zero_grad()
            losses.backward()
            optimizer.step()

            epoch_loss += losses.item()
            progress.set_postfix(loss=losses.item())

        lr_scheduler.step()

        avg_loss = epoch_loss / len(train_loader)
        print(f"âœ… Ep {epoch+1} ì™„ë£Œ | í‰ê·  Loss: {avg_loss:.4f}")

        if avg_loss < best_loss:
            best_loss = avg_loss
            torch.save(model.state_dict(), BEST_SAVE_PATH)
            print(f"   ğŸ† ìµœê³  ì„±ëŠ¥ ê°±ì‹ ! Best Model ì €ì¥ë¨: {os.path.basename(BEST_SAVE_PATH)}")

        if (epoch + 1) % 5 == 0:
            torch.save(model.state_dict(), FINAL_SAVE_PATH)
            print(f"   ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ")

    torch.save(model.state_dict(), FINAL_SAVE_PATH)
    print(f"\n>>> ëª¨ë“  í›ˆë ¨ ì™„ë£Œ! ìµœì¢… ëª¨ë¸ ì €ì¥ë¨: {FINAL_SAVE_PATH}")

if __name__ == '__main__':
    train_mask_rcnn()

import os

# 1. ë“œë¼ì´ë¸Œê°€ ì•„ì§ ë§ˆìš´íŠ¸ ì•ˆ ë˜ì—ˆë‹¤ë©´ ìˆ˜í–‰ (ë˜ì–´ìˆë‹¤ë©´ ê±´ë„ˆëœë‹ˆë‹¤)
if not os.path.exists('/content/drive'):
    from google.colab import drive
    drive.mount('/content/drive')

# --- ì‘ì „ ê²½ë¡œ ì„¤ì • ---

# íƒ€ê²Ÿ íŒŒì¼ ê²½ë¡œ (êµ¬ê¸€ ë“œë¼ì´ë¸Œ)
src_zip_path = '/content/drive/MyDrive/3.á„€á…¢á„‡á…¡á†¼á„ƒá…¦á„‹á…µá„á…¥/1.á„ƒá…¦á„‹á…µá„á…¥/Training/1.á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/5.lower.zip'
label_zip_path = '/content/drive/MyDrive/3.á„€á…¢á„‡á…¡á†¼á„ƒá…¦á„‹á…µá„á…¥/1.á„ƒá…¦á„‹á…µá„á…¥/Training/2.á„…á…¡á„‡á…¦á†¯á„…á…µá†¼á„ƒá…¦á„‹á…µá„á…¥/5.lower.zip'

# ì••ì¶•ì„ í’€ ë¡œì»¬ ëª©ì ì§€ (Colab ë‚´ë¶€)
# ì´ë¦„ì´ ê²¹ì¹˜ì§€ ì•Šê²Œ 'images'ì™€ 'labels'ë¡œ í´ë”ë¥¼ ë‚˜ëˆ´ìŠµë‹ˆë‹¤.
src_dest = '/content/lowerdataset/train/lowerimages'
label_dest = '/content/lowerdataset/train/lowerlabels'

# --- ì‘ì „ ê°œì‹œ (ì••ì¶• í•´ì œ) ---

print(f"ì‘ì „ 1: ì›ì²œ ë°ì´í„°(ì´ë¯¸ì§€) í•´ì œ ì¤‘... \n -> ëª©í‘œì§€ì : {src_dest}")
# í´ë” ìƒì„± (-p: ìƒìœ„ í´ë” ì—†ìœ¼ë©´ ê°™ì´ ìƒì„±)
!mkdir -p "{src_dest}"
# ì••ì¶• í•´ì œ (-qq: ì¡°ìš©íˆ, -d: ëª©ì ì§€ ì§€ì •)
!unzip -qq "{src_zip_path}" -d "{src_dest}"

print(f"ì‘ì „ 2: ë¼ë²¨ë§ ë°ì´í„° í•´ì œ ì¤‘... \n -> ëª©í‘œì§€ì : {label_dest}")
# í´ë” ìƒì„±
!mkdir -p "{label_dest}"
# ì••ì¶• í•´ì œ
!unzip -qq "{label_zip_path}" -d "{label_dest}"

print("======== ì‘ì „ ì„±ê³µ! ëª¨ë“  ë°ì´í„° ì „ê°œ ì™„ë£Œ! ========")