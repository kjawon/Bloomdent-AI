# -*- coding: utf-8 -*-
"""êµ¬ê°•ì¶©ì¹˜ íƒì§€.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y6Rw2lFcOSpTP0EQCKKmKHPq1EpIsRa7
"""

!pip install opencv-python scikit-learn tensorflow

# ================================================================= #
# [Lower] ë¡œì»¬ ë°ì´í„° ê¸°ë°˜ ì¶©ì¹˜ ë¶„ë¥˜ ëª¨ë¸ ì¬í•™ìŠµ (Best Model ì €ì¥)
# ================================================================= #
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from PIL import Image
import os
import glob
from tqdm.auto import tqdm
import numpy as np
import cv2
import json
import random

# ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸
if not os.path.exists('/content/drive'):
    from google.colab import drive
    drive.mount('/content/drive')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f">>> ì‘ì „ ì¥ë¹„: {device}")

# ================================================================= #
# 1. ì„¤ì • (Lower ë¡œì»¬ ê²½ë¡œ ì ìš©)
# ================================================================= #
# â˜…â˜…â˜… [ìˆ˜ì •ë¨] í•˜ì•…(Lower) ë¡œì»¬ ë°ì´í„° ê²½ë¡œ â˜…â˜…â˜…
IMAGE_DIR = '/content/lowerdataset/train/lowerimages'
JSON_DIR = '/content/lowerdataset/train/lowerlabels'

# ëª¨ë¸ ì €ì¥ ê²½ë¡œ
SAVE_DIR = '/content/drive/MyDrive/ëª¨í”„/í•™ìŠµëª¨ë¸/'
if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR, exist_ok=True)

# â˜…â˜…â˜… [ìˆ˜ì •ë¨] íŒŒì¼ëª… ë³€ê²½: upper -> lower â˜…â˜…â˜…
BEST_SAVE_PATH = os.path.join(SAVE_DIR, 'caries_classifier_lower_224_balanced_best.pth')
FINAL_SAVE_PATH = os.path.join(SAVE_DIR, 'caries_classifier_lower_224_balanced_final.pth')

# í•™ìŠµ íŒŒë¼ë¯¸í„°
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 1e-4
POS_WEIGHT_VALUE = 15.0
MAX_DATA_SIZE = 50000

# ================================================================= #
# 2. ë¦¬ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜
# ================================================================= #
def create_train_list(img_dir, json_dir, max_size=50000):
    print(f">>> ğŸ“‚ ë¡œì»¬ ë°ì´í„° ìŠ¤ìº” ì¤‘... (Lower)")

    all_images = glob.glob(os.path.join(img_dir, "*.png"))

    if len(all_images) == 0:
        print("!!! ì˜¤ë¥˜: ì´ë¯¸ì§€ íŒŒì¼ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”!")
        return []

    valid_pairs = []
    for img_path in tqdm(all_images, desc="Pairing"):
        basename = os.path.splitext(os.path.basename(img_path))[0]
        json_path = os.path.join(json_dir, f"{basename}.json")

        if os.path.exists(json_path):
            valid_pairs.append({'image_path': img_path, 'json_path': json_path})

    print(f"   - ë§¤ì¹­ëœ íŒŒì¼ ìŒ: {len(valid_pairs)}ê°œ")

    if len(valid_pairs) > max_size:
        random.shuffle(valid_pairs)
        valid_pairs = valid_pairs[:max_size]
        print(f"   - {max_size}ê°œë¡œ ë°ì´í„°ë¥¼ ì œí•œí•©ë‹ˆë‹¤.")

    return valid_pairs

# ================================================================= #
# 3. ë°ì´í„°ì…‹ í´ë˜ìŠ¤
# ================================================================= #
class CariesCropDataset(Dataset):
    def __init__(self, file_list, img_size):
        self.samples = []
        self.img_size = img_size

        print(f">>> ì¹˜ì•„ í¬ë¡­ ë°ì´í„°ì…‹ êµ¬ì¶• ì¤‘...")

        for item in tqdm(file_list):
            img_path = item['image_path']
            json_path = item['json_path']

            try:
                with open(json_path, 'r') as f: data = json.load(f)
                for tooth in data.get('tooth', []):
                    gt_seg = np.array(tooth.get('segmentation', []), dtype=np.int32)
                    if len(gt_seg) == 0: continue
                    x, y, w, h = cv2.boundingRect(gt_seg)
                    decayed = 1 if tooth.get('decayed', False) else 0

                    self.samples.append({
                        'img_path': img_path, 'bbox': (x, y, w, h), 'label': decayed
                    })
            except: continue

        print(f">>> ì´ í•™ìŠµìš© ì¹˜ì•„ ìƒ˜í”Œ: {len(self.samples)}ê°œ")

        self.transform = transforms.Compose([
            transforms.Resize(self.img_size),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(15),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

    def __len__(self): return len(self.samples)

    def __getitem__(self, idx):
        item = self.samples[idx]
        try:
            img = cv2.imread(item['img_path'])
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            x, y, w, h = item['bbox']
            crop = img[y:y+h, x:x+w]
            if crop.size == 0: raise ValueError("Empty crop")

            crop_pil = Image.fromarray(crop)
            img_tensor = self.transform(crop_pil)
            label_tensor = torch.tensor([item['label']], dtype=torch.float32)
            return img_tensor, label_tensor
        except:
            return self.__getitem__((idx + 1) % len(self.samples))

# ================================================================= #
# 4. ëª¨ë¸ ë° í•™ìŠµ ë£¨í”„
# ================================================================= #
class CariesClassifier(nn.Module):
    def __init__(self, num_classes=1):
        super().__init__()
        try: self.base_model = models.resnet50(weights='DEFAULT')
        except: self.base_model = models.resnet50(weights='IMAGENET1K_V1')

        self.base_model.fc = nn.Sequential(
            nn.Linear(self.base_model.fc.in_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, num_classes)
        )
    def forward(self, x): return self.base_model(x)

def train_classifier():
    # 1. ë¡œì»¬ íŒŒì¼ ìŠ¤ìº” (Lower)
    file_list = create_train_list(IMAGE_DIR, JSON_DIR, MAX_DATA_SIZE)

    if not file_list: return

    # 2. ë°ì´í„°ì…‹ ìƒì„±
    dataset = CariesCropDataset(file_list, IMAGE_SIZE)

    if len(dataset) == 0:
        print("!!! ì¶”ì¶œëœ ì¹˜ì•„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    train_size = int(0.9 * len(dataset))
    val_size = len(dataset) - train_size
    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

    model = CariesClassifier(1).to(device)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    pos_weight = torch.tensor([POS_WEIGHT_VALUE]).to(device)
    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)

    print(f"\n>>> ğŸš€ [Lower] ë¶„ë¥˜ ëª¨ë¸ ì¬í•™ìŠµ ì‹œì‘ (Best Model ì €ì¥)")

    best_val_loss = float('inf')

    for epoch in range(EPOCHS):
        model.train()
        train_loss = 0
        loop = tqdm(train_loader, desc=f"Ep {epoch+1}/{EPOCHS}", leave=False)

        for img, label in loop:
            img, label = img.to(device), label.to(device)
            pred = model(img)
            loss = criterion(pred, label)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            loop.set_postfix(loss=loss.item())

        # ê²€ì¦
        model.eval()
        val_loss = 0
        tp, fn, fp = 0, 0, 0

        with torch.no_grad():
            for img, label in val_loader:
                img, label = img.to(device), label.to(device)
                out = model(img)
                val_loss += criterion(out, label).item()

                pred_prob = torch.sigmoid(out)
                predicted = (pred_prob > 0.5).float()

                is_caries = (label == 1)
                is_normal = (label == 0)
                tp += (predicted[is_caries] == 1).sum().item()
                fn += (predicted[is_caries] == 0).sum().item()
                fp += (predicted[is_normal] == 1).sum().item()

        avg_val_loss = val_loss / len(val_loader)
        recall = tp / (tp + fn + 1e-6)
        precision = tp / (tp + fp + 1e-6)

        print(f"âœ… Ep {epoch+1} | Loss:{avg_val_loss:.4f} | â˜…Recall:{recall:.4f} | Prec:{precision:.4f}")

        # Best Model ì €ì¥
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), BEST_SAVE_PATH)
            print(f"   ğŸ† ìµœê³  ì„±ëŠ¥ ê°±ì‹ ! ì €ì¥ë¨: {os.path.basename(BEST_SAVE_PATH)}")

    # Final Model ì €ì¥
    torch.save(model.state_dict(), FINAL_SAVE_PATH)
    print(f"\n>>> í•™ìŠµ ì™„ë£Œ! ìµœì¢… ëª¨ë¸ ì €ì¥ë¨: {FINAL_SAVE_PATH}")

if __name__ == '__main__':
    train_classifier()

import os

# 1. ë“œë¼ì´ë¸Œê°€ ì•„ì§ ë§ˆìš´íŠ¸ ì•ˆ ë˜ì—ˆë‹¤ë©´ ìˆ˜í–‰ (ë˜ì–´ìˆë‹¤ë©´ ê±´ë„ˆëœë‹ˆë‹¤)
if not os.path.exists('/content/drive'):
    from google.colab import drive
    drive.mount('/content/drive')

# --- ì‘ì „ ê²½ë¡œ ì„¤ì • ---

# íƒ€ê²Ÿ íŒŒì¼ ê²½ë¡œ (êµ¬ê¸€ ë“œë¼ì´ë¸Œ)
src_zip_path = '/content/drive/MyDrive/3.á„€á…¢á„‡á…¡á†¼á„ƒá…¦á„‹á…µá„á…¥/1.á„ƒá…¦á„‹á…µá„á…¥/Training/1.á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/5.lower'
label_zip_path = '/content/drive/MyDrive/3.á„€á…¢á„‡á…¡á†¼á„ƒá…¦á„‹á…µá„á…¥/1.á„ƒá…¦á„‹á…µá„á…¥/Training/2.á„…á…¡á„‡á…¦á†¯á„…á…µá†¼á„ƒá…¦á„‹á…µá„á…¥/5.lower.zip'

# ì••ì¶•ì„ í’€ ë¡œì»¬ ëª©ì ì§€ (Colab ë‚´ë¶€)
# ì´ë¦„ì´ ê²¹ì¹˜ì§€ ì•Šê²Œ 'images'ì™€ 'labels'ë¡œ í´ë”ë¥¼ ë‚˜ëˆ´ìŠµë‹ˆë‹¤.
src_dest = '/content/lowerdataset/train/lowerimages'
label_dest = '/content/lowerdataset/train/lowerlabels'

# --- ì‘ì „ ê°œì‹œ (ì••ì¶• í•´ì œ) ---

print(f"ì‘ì „ 1: ì›ì²œ ë°ì´í„°(ì´ë¯¸ì§€) í•´ì œ ì¤‘... \n -> ëª©í‘œì§€ì : {src_dest}")
# í´ë” ìƒì„± (-p: ìƒìœ„ í´ë” ì—†ìœ¼ë©´ ê°™ì´ ìƒì„±)
!mkdir -p "{src_dest}"
# ì••ì¶• í•´ì œ (-qq: ì¡°ìš©íˆ, -d: ëª©ì ì§€ ì§€ì •)
!unzip -qq "{src_zip_path}" -d "{src_dest}"

print(f"ì‘ì „ 2: ë¼ë²¨ë§ ë°ì´í„° í•´ì œ ì¤‘... \n -> ëª©í‘œì§€ì : {label_dest}")
# í´ë” ìƒì„±
!mkdir -p "{label_dest}"
# ì••ì¶• í•´ì œ
!unzip -qq "{label_zip_path}" -d "{label_dest}"

print("======== ì‘ì „ ì„±ê³µ! ëª¨ë“  ë°ì´í„° ì „ê°œ ì™„ë£Œ! ========")